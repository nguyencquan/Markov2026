\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage[margin=.5in]{geometry}
\setlength{\parindent}{0pt}

\title{Homework 1}
\author{Quan Nguyen}
\date{January 2026}

\begin{document}

\maketitle
See https://github.com/nguyencquan/Markov2026 for code used in simulations.

\section{Power Law Sampling}
Assume we have some distribution
\begin{equation}
    \begin{cases}
    Cx^{-\gamma}& x\geq x_0,\\
    0, & x<x_0
\end{cases}
\end{equation}
\textbf{a)}
Where $x_0>0$ and $\gamma > 3$

A valid pdf must have a total probability of 1, which is calculated below:
\begin{equation}
    1 = \int_{-\infty}^{\infty}Cx^{-\gamma}dx = C\int_{x_0}^{\infty}x^{-\gamma}dx
    =\frac{C}{x^{\gamma-1}(1-\gamma)}\vert_{x_0}^\infty = \frac{C}{x_0^{\gamma-1}(\gamma-1)}
\end{equation}
\begin{equation}
    C = x_0^{\gamma-1}(\gamma-1)\\
\end{equation}

\textbf{b)}
First calculating the cummulative distribution we take a step from equation 2 except take the integral from
$x_0$ to $x$ instead.

\begin{equation}
    1 = \int_{-\infty}^{\infty}Cx^{-\gamma}dx = C\int_{x_0}^{x}x^{-\gamma}dx
    =\frac{C}{x^{\gamma-1}(1-\gamma)}\vert_{x_0}^x = \frac{C}{x_0^{\gamma-1}(\gamma-1)} + \frac{C}{x^{\gamma-1}(1-\gamma)}
\end{equation}
Substituting in C
\begin{equation}
    F(x) = 
    \begin{cases}
        1 - \frac{x_0^{\gamma-1}}{x^{\gamma-1}}, & x \geq x_0\\
        0, & x< x_0
    \end{cases}
\end{equation}

To calculate the inverse, note we can do root math since $x_0>0$
\begin{align}
    p &= 1 - \frac{x_0^{\gamma-1}}{x^{\gamma-1}}\\
    \frac{x_0^{\gamma-1}}{x^{\gamma-1}} &= 1-p\\
    \frac{x_0}{x} &= (1-p)^\frac{1}{\gamma-1}\\
    x &= \frac{x_0}{(1-p)^\frac{1}{\gamma-1}}
\end{align}

\textbf{c)} Also we can note that we can use $U(0,1)$ without $1-p$ to speed it up since their distribution is
exactly the same.


1. Sample from a normal distribution $U(0,1)$

2. substitue value into p for $\frac{x_0}{p^\frac{1}{\gamma-1}}$

\textbf{d)}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{100Samples.png}
    \caption{Graph of pdf and random sampling of 100 points, given $\gamma = 4$ and $x_0 = 10$}
    \label{fig:myimage}
\end{figure}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{1000Samples.png}
    \caption{Graph of pdf and random sampling of 1000 points, given $\gamma = 4$ and $x_0 = 10$}
    \label{fig:myimage}
\end{figure}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{10000Samples.png}
    \caption{Graph of pdf and random sampling of 10000 points, given $\gamma = 4$ and $x_0 = 10$}
    \label{fig:myimage}
\end{figure}

\newpage
\section{Gamma Sampling}

Suppose we have $X\sim Gamma(2,1)$ with pdf
\begin{equation}
    f(x) = \begin{cases}
        x e^{-x}, & x > 0\\
        0, & x \leq 0
    \end{cases}
\end{equation}
\textbf{a)} To calculate the CDF we take the integral of the pdf from 0 to x.
Using integration by part with $u = x$ and $dv = e^{-x}$
\begin{align}
    \int_{-\infty}^{x}f(x)dx = \int_0^x xe^{-x}dx &=-xe^{-x}+\int_{0}^{x}e^{-x}dx\\
    &=-e^{-x}(x+1)|_{0}^x\\
    &=1-e^{-x}(x+1)
\end{align}
Hence we have
\begin{equation}
    F(x) = 
    \begin{cases}
        1-e^{-x}(x+1), & x> 0\\
        0, & x\leq 0
    \end{cases}
\end{equation}
\textbf{b}
I will be using Newtons method to find the inverse of the CDF. The method will guess a root at one and runs 5
times then repeated until the root is positive. There is a sanity check where if the root stays negative
an error occurs. Fortunately the code works. The solution to the CDF will be calcualted by solving the root of $F(x)-u = 0$.
The function took 5.1287 seconds to run.

\textbf{c}
To solve for the optimal value for c, I will use the inequality:

\begin{align}
    C\frac12e^{-\frac{x}{2}}&\geq xe^{-x}\\
    C & \geq 2 xe^{\frac{-x}{2}} = h(x)\\
\end{align}

To solve for the critical point of the equation, take the derivative and solve 
for the roots 
\begin{align}
    h'(x) &= 2e^{\frac{-x}{2}} - xe^{\frac{-x}{2}}\\
    &= e^{\frac{-x}{2}}(2-x) = 0\\
\end{align}

Since the derivative is a strictly decreasing function and is positive when $x<2$, the critical value
is the point where $h(x)$ is the absolute maximum yielding
\begin{equation}
    C \geq h(2) = 4/e
\end{equation}

Since efficiency is determined by $1/C$ the smallest possible value of C to maximize efficiency is
$4/e$.

Also note that the given distribution $g(x)$ is aa pdf for an exponential distribution with $\lambda = 1/2$
Using an acceptace rejection algorithm, it took 3.1873 seconds to complete.

\textbf{d} 
After running the simulation code, the experiment was completed in 0.0872 seconds.

\textbf{f} The fastest algorithm is summing the exponential distributions, then it is the
acceptance-rejection criterion, and the slowest is using the root solver. Note the root solver
doesn't even give very accurate results and takes even more time if I want it to be more accurate.

\textbf{g}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{pdfAcceptReject.png}
    \caption{Graph for the pdf of $xe^{-x}$ using acceptance rejection criterion.}
    \label{fig:myimage}
\end{figure}

\section{Mixture Sampling to Polynomial Sampling}

\textbf{a} To show that these two distributions are the same, we will be calculating the CDF
of Y. Note the main proof follows the law of total probability:
\begin{align}
    Y(y) = P(Y\leq y) &= \sum_{j = 1}^N P(X_J \leq y| J = j)P(J = j)\\
    &= \sum_{j=1}^{N} P(X_j\leq y)P(J=j)\\
    &= \sum_{j=1}^{N} P(X_j\leq y)a_j\\
    &= \sum_{j=1}^{N}\int_0^y f_j(x)dx a_j\\
    &= \sum_{j=1}^{N}\int_0^y f_j(x)a_jdx\\
    &= \int_{0}^{y}\sum_{j=1}^{N} a_jf_j(x)dx\\
    &= \int_{0}^y f(x)dx = F(y)
\end{align}

\textbf{b} To solve for the CDF, I will be taking the integral of $f_j$ from 0 to x.
\begin{equation}
    \int_0^x f_j(x)dx = \int_{0}^{x} (j+1)x^jdx = =x^{j+1}|_0^x = x^{j+1}
\end{equation}

To sample from this distribution I will use inverse sampling. The inverse of the CDF is $x = u^\frac{1}{j+1}$.
Hence the pseudo code will be.

1. Generate a random value $u\sim U(0,1)$

2. return $u^\frac{1}{j+1}$


\textbf{c} I will be finding a way to setup $f(z)$ Using the sum that is given above. Since
the highest power of $f(z)$ is $5$, $N = 5$ resulting in the following sum:
\begin{equation}
    \sum_{j=1}^5a_jf_j(z) = a_12z + a_23z^2 + a_34z^3 + a_45z^4 + a_56z^5
\end{equation}
Furthermore $a_1 = \frac12, a_5 = \frac12$ while all other $a_j$ equal 0. Using
the fact from question a due to the law of total probability, we can do conditional sampling.

1. Sample $j\sim U(0,1)$

2. if $j \geq .5$ $j=1$ else $j=5$

3. generate $u\sim U(0,1)$

4. return $u^\frac{1}{j+1}$

\end{document}